In this section we want to address work that we were not able to complete in time or ideas we find worthwhile considering.

\subsection{Handle Multiple Planning Results}
\label{sec:multiple-results}

Even though we were able to implement concurrently running planners, we were short on time to properly use the additionally generated plans. In the current state, the agent is able to run the new 2017 planner as well as the 2016 version concurrently, combining both their returned plans into one ordered list. The issue, however, is that both planners use different ways to rate their plans: the 2017 version uses a shot confidence with values between 0 and 1 while the 2016 version uses a point based ranking without upper boundary. It is thus impossible to simply combine both results, since the 2016 version would always be favoured over the version of 2017. In an attempted workaround we only used plans of the 2016 version if the 2017 version would fail to return any plans or the plans were known to be bad from previous attempts at the same level. With this extensible framework and a way to properly compare or handle plans with different rating systems, this could be a highly beneficial addition to the meta reasoning of the agent.

\subsection{Revise Generation of Knowledge Representation}

While working on our strategies, we discovered quite a few inconsistencies within the knowledge representation in form of the situation-files. For example, there are cases in which the \emph{isLeft} and \emph{isRight} predicates are not symmetric, i.e. a is left of b while b is not right of a. We were able to track some other issues down (\emph{isAbove} and \emph{isHittable} as mentioned in \ref{sec:refandfix}), but there might be more we were not able to find. Another big issue we faced was the structure detection algorithm, as it was too imprecise for our purposes. Piles of rubble in shots 2 and beyond were often detected as multiple structures, corrupting the results of our planner.

\subsection{Increase Robustness of the Agent}

As made apparent by the benchmark and the results of the competition, the agent, in its current state, can get stuck on a level. Since this will lose us the most points (see \ref{sec:eval}), increasing the robustness of the agent in the case of a crash is most important. Apart from the crash issue, the agent will need improving on solving levels, be it with a lower score. Also, reducing the time needed for the shot selection (see also \ref{sec:eval}) may further increase the beneficial influence of the meta strategies in place.

\subsection{Rebalance Strategies}

The benchmark in \ref{sec:eval} shows that the shot planner is most confident which may not be the best to take because of the big profit of the meta analysis. As long as the agent is not able to replay levels to a greater extent, it is important to rebalance certain specialized strategies. Thus, some strategies should be made not applicable in certain situations by reducing their confidence, e.g. playing \emph{collapseStructure} on rubble falsely detected as a structure.